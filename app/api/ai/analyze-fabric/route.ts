// API endpoint ƒë·ªÉ ph√¢n t√≠ch ·∫£nh v·∫£i b·∫±ng Google Gemini Vision API
// POST /api/ai/analyze-fabric

import { NextRequest, NextResponse } from 'next/server'

export interface FabricAnalysisResult {
  material: string // Ch·∫•t li·ªáu
  color: string // M√†u s·∫Øc
  pattern: string // H·ªça ti·∫øt
  confidence: number // 0-1
  analysis_notes: string
  name?: string // T√™n v·∫£i (n·∫øu AI ƒë·ªçc ƒë∆∞·ª£c t·ª´ ·∫£nh)
  origin?: string // Xu·∫•t x·ª© (Trung Qu·ªëc, H√†n Qu·ªëc, Vi·ªát Nam, √ù, Ph√°p...)
  width?: number // Chi·ªÅu r·ªông (cm)
  weight?: number // Tr·ªçng l∆∞·ª£ng (g/m¬≤)
  price_estimate?: number // Gi√° ∆∞·ªõc l∆∞·ª£ng (VNƒê/m)
}

interface ApiResponse<T> {
  success: boolean
  data?: T
  error?: string
}

export async function POST(request: NextRequest) {
  try {
    const formData = await request.formData()
    const imageFile = formData.get('image') as File
    
    if (!imageFile) {
      return NextResponse.json({
        success: false,
        error: 'Kh√¥ng t√¨m th·∫•y ·∫£nh ƒë·ªÉ ph√¢n t√≠ch'
      } as ApiResponse<null>, { status: 400 })
    }

    // Validate file type
    if (!imageFile.type.startsWith('image/')) {
      return NextResponse.json({
        success: false,
        error: 'File kh√¥ng ph·∫£i l√† ·∫£nh'
      } as ApiResponse<null>, { status: 400 })
    }

    // Convert image to base64 and compress if needed
    const bytes = await imageFile.arrayBuffer()
    let buffer = Buffer.from(bytes)
    const mimeType = imageFile.type

    // Compress image if larger than 500KB to avoid 413 error
    const maxSize = 500 * 1024 // 500KB
    if (buffer.length > maxSize) {
      console.log('üóúÔ∏è Compressing image from', (buffer.length / 1024).toFixed(2), 'KB')

      // Use sharp to compress image
      const sharp = require('sharp')

      // Resize to max 800px width while maintaining aspect ratio
      buffer = await sharp(buffer)
        .resize(800, null, {
          fit: 'inside',
          withoutEnlargement: true
        })
        .jpeg({ quality: 75 })
        .toBuffer()

      console.log('‚úÖ Compressed to', (buffer.length / 1024).toFixed(2), 'KB')
    }

    const base64Image = buffer.toString('base64')

    // Get API key from environment
    const apiKey = process.env.GEMINI_API_KEY

    if (!apiKey) {
      return NextResponse.json({
        success: false,
        error: 'Gemini API key ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh. Vui l√≤ng th√™m GEMINI_API_KEY v√†o file .env'
      } as ApiResponse<null>, { status: 500 })
    }

    console.log('ü§ñ Analyzing fabric image with Gemini Vision...')
    console.log(`üì∏ Compressed size: ${(buffer.length / 1024).toFixed(2)} KB`)
    console.log(`üìù MIME type: ${mimeType}`)

    // Prepare prompt - Y√™u c·∫ßu AI ph√¢n t√≠ch ƒë·∫ßy ƒë·ªß th√¥ng tin
    const prompt = `Ph√¢n t√≠ch ·∫£nh v·∫£i n√†y v√† tr·∫£ v·ªÅ JSON v·ªõi c√°c th√¥ng tin sau:

{
  "material": "Ch·∫•t li·ªáu (Cotton/Polyester/Silk/Linen/Wool/Blend/Satin/Chiffon/Organza/Taffeta/Velvet...)",
  "color": "M√†u s·∫Øc ch√≠nh (ti·∫øng Vi·ªát, v√≠ d·ª•: Xanh navy, ƒê·ªè ƒë√¥, Tr·∫Øng kem...)",
  "pattern": "H·ªça ti·∫øt (Tr∆°n/K·∫ª s·ªçc/Hoa vƒÉn/Ch·∫•m bi/Caro/H·ªça ti·∫øt h√¨nh h·ªçc...)",
  "confidence": 0.85,
  "analysis_notes": "M√¥ t·∫£ chi ti·∫øt v·ªÅ v·∫£i (ƒë·ªô b√≥ng, k·∫øt c·∫•u, ƒë·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t...)",
  "name": "T√™n v·∫£i n·∫øu c√≥ th·ªÉ ƒë·ªçc ƒë∆∞·ª£c t·ª´ ·∫£nh (null n·∫øu kh√¥ng c√≥)",
  "origin": "Xu·∫•t x·ª© n·∫øu nh·∫≠n di·ªán ƒë∆∞·ª£c (Trung Qu·ªëc/H√†n Qu·ªëc/Vi·ªát Nam/√ù/Ph√°p/Nh·∫≠t B·∫£n... ho·∫∑c null)",
  "width": 150,
  "weight": 200,
  "price_estimate": 50000
}

**L∆∞u √Ω quan tr·ªçng:**
- Ch·ªâ ƒëi·ªÅn th√¥ng tin n·∫øu CH·∫ÆC CH·∫ÆN, n·∫øu kh√¥ng ch·∫Øc th√¨ ƒë·ªÉ null
- width: Chi·ªÅu r·ªông ti√™u chu·∫©n c·ªßa lo·∫°i v·∫£i n√†y (cm), v√≠ d·ª•: Cotton th∆∞·ªùng 140-150cm, Silk 90-114cm
- weight: Tr·ªçng l∆∞·ª£ng ∆∞·ªõc l∆∞·ª£ng d·ª±a tr√™n ch·∫•t li·ªáu v√† ƒë·ªô d√†y (g/m¬≤), v√≠ d·ª•: Cotton m·ªèng 100-150, d√†y 200-300
- price_estimate: Gi√° ∆∞·ªõc l∆∞·ª£ng th·ªã tr∆∞·ªùng Vi·ªát Nam (VNƒê/m), d·ª±a tr√™n ch·∫•t li·ªáu v√† ch·∫•t l∆∞·ª£ng
- origin: Ch·ªâ ƒëi·ªÅn n·∫øu c√≥ d·∫•u hi·ªáu r√µ r√†ng (nh√£n m√°c, ƒë·∫∑c ƒëi·ªÉm ƒë·∫∑c tr∆∞ng...)
- name: Ch·ªâ ƒëi·ªÅn n·∫øu ƒë·ªçc ƒë∆∞·ª£c text/nh√£n tr√™n ·∫£nh

Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng gi·∫£i th√≠ch th√™m.`

    // Call Gemini Vision API (Updated to gemini-2.5-flash)
    const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${apiKey}`

    const response = await fetch(apiUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        contents: [
          {
            parts: [
              {
                text: prompt
              },
              {
                inline_data: {
                  mime_type: mimeType,
                  data: base64Image
                }
              }
            ]
          }
        ],
        generationConfig: {
          temperature: 0.3,
          maxOutputTokens: 2048,
          responseMimeType: 'application/json'
        }
      })
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error('‚ùå Gemini API error:', errorText)

      return NextResponse.json({
        success: false,
        error: `Gemini API error: ${response.status} ${response.statusText}`
      } as ApiResponse<null>, { status: response.status })
    }

    const result = await response.json()
    console.log('‚úÖ Gemini API response:', JSON.stringify(result, null, 2))

    // Extract analysis from response
    const content = result.candidates?.[0]?.content?.parts?.[0]?.text
    if (!content) {
      console.error('‚ùå No content in response:', JSON.stringify(result, null, 2))

      // Check for finish reason
      const finishReason = result.candidates?.[0]?.finishReason
      if (finishReason === 'MAX_TOKENS') {
        return NextResponse.json({
          success: false,
          error: 'AI response b·ªã c·∫Øt ng·∫Øn (MAX_TOKENS). Vui l√≤ng th·ª≠ l·∫°i.'
        } as ApiResponse<null>, { status: 500 })
      }

      return NextResponse.json({
        success: false,
        error: 'Kh√¥ng nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£ ph√¢n t√≠ch t·ª´ AI'
      } as ApiResponse<null>, { status: 500 })
    }

    // Parse JSON response
    let analysis: FabricAnalysisResult
    try {
      analysis = JSON.parse(content)
    } catch (parseError) {
      console.error('‚ùå Failed to parse AI response:', content)
      return NextResponse.json({
        success: false,
        error: 'Kh√¥ng th·ªÉ parse k·∫øt qu·∫£ ph√¢n t√≠ch t·ª´ AI'
      } as ApiResponse<null>, { status: 500 })
    }

    console.log('‚úÖ Fabric analysis completed:', analysis)

    // Return analysis result
    return NextResponse.json({
      success: true,
      data: analysis
    } as ApiResponse<FabricAnalysisResult>)

  } catch (error) {
    console.error('‚ùå Error analyzing fabric:', error)
    
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error.message : 'L·ªói kh√¥ng x√°c ƒë·ªãnh khi ph√¢n t√≠ch ·∫£nh'
    } as ApiResponse<null>, { status: 500 })
  }
}
